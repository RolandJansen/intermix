<html>

<head>
    <title>Sequencer Demo</title>
    <script type='module' src='/dist/esm/index.js'></script>
    <script type='text/javascript' src='https://cdn.jsdelivr.net/npm/nexusui@2.0.13/dist/NexusUI.min.js'></script>
    <style>
        html {
            font-family: Arial, Helvetica, sans-serif;

        }

        .button-group div {
            /* float: left; */
            display: inline-block;
        }

        #blink {
            width: 20px;
            height: 20px;
            border-style: solid;
        }

        .note {
            font-size: small;
        }
    </style>
</head>

<!-- <body onload="init();"> -->

<body>
    <button id="resumeAudioContext">resume audio context</button>
    <button id="getstate">get current state</button>
    <div id="sequencer"></div>
    <div class="button-group">
        <div id="start-button"></div>
        <div id="stop-button"></div>
        <!-- <div id="reset-button"></div> -->
        <div id="set-bpm"></div>
    </div>
    <!-- <div id="blink"></div> -->
    <p class="note">Note: This demo is done with NexusUI which turned out to be not ideal.
        The sequencer UI doesn't work well together with the
        intermix sequencer and will soon be replaced with more
        suitable elements.

    </p>
</body>
<script>
    // redux is reading the 'process' global var
    // that doesn't exists in the browser
    const process = {
        env: {
            NODE_ENV: 'debug',
        }
    };
</script>
<script type="module">
    import {
        addPlugin,
        addSeqPart,
        getActionCreators,
        getAudioContext,
        getState,
        resumeAudioContext,
    } from "/dist/index.js";

    let BPM = 120;

    const sequencer = new Nexus.Sequencer('#sequencer', {
        size: [540, 200],
        rows: 4,
        columns: 16,
    })
    const startButton = new Nexus.TextButton('#start-button', {
        text: 'Start',
    })
    const stopButton = new Nexus.TextButton('#stop-button', {
        text: 'Stop',
    })
    // const resetButton = new Nexus.TextButton('#reset-button', {
    //     text: 'Reset',
    // })
    const setBpm = new Nexus.Number('#set-bpm', {
        size: [80, 50],
        value: BPM,
        min: 0,
        max: 240,
    })

    startButton.on('change', (e) => {
        // e: true -> mousedown
        if (e) {
            sequencer.stepper.value = -1;
            seqActionCreators.start();
        }
    })

    stopButton.on('change', (e) => {
        // e: true -> mousedown
        if (e) {
            seqActionCreators.stop();
            seqActionCreators.reset();
        }
    })

    // resetButton.on('change', (e) => {
    //     // e: true -> mousedown
    //     if (e) {
    //         seqActionCreators.reset();
    //         // sequencer.stepper.value = -1;
    //         // const counter = new Nexus.Counter(0, 1);
    //         // counter.value = 0;
    //         // sequencer.stepper(counter);
    //     }
    // })

    setBpm.on('change', (e) => {
        // e: true -> mousedown
        if (e) {
            BPM = e;
            seqActionCreators.BPM(e);
        }
    })

    sequencer.on('change', (e) => {
        const partId = seqPartUID[e.row];
        const instrumentId = instrumentUID[e.row];
        const partActionCreators = getActionCreators(partId);
        const duration = get16thDuration(BPM);
        if (e.state) {
            // send an "addNote" action to the according part
            partActionCreators.activeStep(e.column);
            partActionCreators.addNote(["note", 40, 1, duration, 0.0]);
        } else {
            // send a "deleteNote" action to the according part
            partActionCreators.activeStep(e.column);
            partActionCreators.removeNote(["note", 40, 1, duration, 0.0]);
        }
    })

    const selectNextSeqRow = (step) => {
        if (step % 4 === 0) {
            sequencer.next();
        }
    }

    const ac = getAudioContext();
    const instrumentUID = [];
    const seqPartUID = [];
    let sequencerUID = '';

    let synthUID = "";
    let seqActionCreators = {};
    let samplerActionCreators = {};

    let samples = [
        "/demo/assets/Casio SK-1/skkick.wav",
        "/demo/assets/Casio SK-1/sksnare.wav",
        "/demo/assets/Casio SK-1/skclhat.wav",
        "/demo/assets/Casio SK-1/skophat.wav",
    ]

    export function init() {

        // create sampler plugins and a sequencer part for each sound
        for (let i = 0; i < 4; i++) {
            instrumentUID.push(addPlugin('Sampler'))
            seqPartUID.push(addSeqPart())  // 16 steps if not stated otherwise
        }

        // add a sample to each sampler
        samples.forEach((sample, index) => {
            addAudioDataToSampler(instrumentUID[index], sample);
        })

        // setup the sequencer
        sequencerUID = addPlugin('Sequencer');
        seqActionCreators = getActionCreators(sequencerUID);
        seqActionCreators.animate(selectNextSeqRow);  // animate the sequencer

        console.log(seqActionCreators);

        // setup a basic sequence
        sequencer.matrix.populate.row(0, [1, 0, 0, 0, 0, 0, 0, 0]);
        sequencer.matrix.populate.row(1, [0, 0, 0, 0, 1, 0, 0, 0]);
        sequencer.matrix.populate.row(2, [0, 0, 1, 0]);

        // add notes to the seqParts
        // populateSeqParts(sequencer.matrix.pattern);

        // add parts to sequencer and to the score
        seqPartUID.forEach((seqPartId, index) => {
            seqActionCreators.addToScore([seqPartId, instrumentUID[index]])
        })

        // play in loop mode
        // seqActionCreators.loopActive();
        seqActionCreators.loopActivate();

    }

    const loadFile = (url) => {
        return window.fetch(url)
            .then((response) => {
                if (response.ok) {
                    return response.arrayBuffer();
                } else {
                    throw new Error('Server error. Couldn\'t load file: ' + url);
                }
            });
    };

    const addAudioDataToSampler = (samplerUID, rawData) => {
        loadFile(rawData).then((response) => {
            return ac.decodeAudioData(response);
        }).then((decoded) => {
            // send the audio buffer to the sampler
            const actionCreators = getActionCreators(samplerUID)
            actionCreators.audioData(decoded)
        })
    }

    const populateSeqParts = (matrix) => {
        matrix.forEach((seqRow, rowIndex) => {
            const seqPartId = seqPartUID[rowIndex];
            const samplerId = instrumentUID[rowIndex];
            const seqPartActionCreators = getActionCreators(seqPartId);
            // const duration = get16thDuration()

            seqRow.forEach((seqStep, stepIndex) => {
                if (seqRow[stepIndex] === true) {
                    seqPartActionCreators.addNote(["note", 40, 1, 1.0, 0.0]);
                }
            })
        })
    }

    const get16thDuration = (bpm) => {
        const divisor = bpm * 4;
        return 60 / divisor;
    }

    document.getElementById('resumeAudioContext').addEventListener('click', () => {
        resumeAudioContext();
        console.log("Audio Context Resumed");
    });

    document.getElementById("getstate").addEventListener('click', () => {
        console.log(getState());
    })

    init();

</script>

</html>