<html>

<head>
    <title>Sequencer Demo</title>
    <style>
        html {
            font-family: Arial, Helvetica, sans-serif;

        }
        .button-group div {
            /* float: left; */
            display: inline-block;
        }
        #blink {
            width: 20px;
            height: 20px;
            border-style: solid;
        }
    </style>
</head>

<body onload="init();">
    <button id="resumeAudioContext">resume audio context</button>
    <button id="getstate">get current state</button>
    <button id="getPattern">get Pattern</button>
    <div id="sequencer"></div>
    <div class="button-group">
        <div id="start-button"></div>
        <div id="pause-button"></div>
        <div id="stop-button"></div>
        <div id="set-bpm"></div>
    </div>
    <!-- <div id="blink"></div> -->
</body>
<script>

    const sequencer = new Nexus.Sequencer('#sequencer', {
        size: [540, 200],
        rows: 4,
        columns: 16,
    })
    const startButton = new Nexus.TextButton('#start-button', {
        text: 'Start',
    })
    const pauseButton = new Nexus.TextButton('#pause-button', {
        text: 'Pause',
    })
    const stopButton = new Nexus.TextButton('#stop-button', {
        text: 'Stop',
    })
    const setBpm = new Nexus.Number('#set-bpm', {
        size: [80, 50],
        value: 120,
        min: 0,
        max: 240,
    })

    startButton.on('change', (e) => {
        // send a start action to the sequencer
    })

    const selectNextSeqRow = (step) => {
            if (step % 16 === 0) {
                sequencer.next();
            }
        }

        const ac = intermix.getAudioContext();
    const samplerUID = [];
    const seqPartUID = [];
    let sequencerUID = '';

    let synthUID = "";
    let seqActionCreators = {};
    let samplerActionCreators = {};

    let samples = [
        demo.skkick,
        demo.sksnare,
        demo.skclhat,
        demo.skophat,
    ]

    const loadFile = (url) => {
        return window.fetch(url)
            .then((response) => {
                if (response.ok) {
                    return response.arrayBuffer();
                } else {
                    throw new Error('Server error. Couldn\'t load file: ' + url);
                }
            });
        };

        const addAudioDataToSampler = (samplerUID, rawData) => {
            loadFile(rawData).then((response) => {
            return ac.decodeAudioData(response);
        }).then((decoded) => {
            const audioDataAction = {
                type: "AUDIODATA",
                dest: samplerUID,
                payload: decoded,
            };
            // send the audio buffer to the sampler
            const actionCreators = intermix.getActionCreators(samplerUID)
            actionCreators.AUDIODATA(audioDataAction)
        })
    }

    function getNote(value, steps, uid) {
        const velocity = 1;
        const duration = 0;
        return {
            type: "NOTE",
            dest: uid,
            payload: {
                value,
                velocity,
                steps,
                duration,
            }
        }
    }

    function init() {
        sequencerUID = intermix.addPlugin('Sequencer');

        // create 5 sampler plugins and 5 sequencer parts
        for (let i = 0; i < 4; i++) {
            samplerUID.push(intermix.addPlugin('DemoSampler'))
            seqPartUID.push(intermix.addSeqPart())  // 16 steps if not stated otherwise
        }

        samples.forEach((sample, index) => {
            addAudioDataToSampler(samplerUID[index], sample["default"]);
        })

        intermix.animate(selectNextSeqRow);  // animate the sequencer
    }

    // const ac = intermix.getAudioContext();
    // const synthPart1 = intermix.getNewPart();
    // const synthPart2 = intermix.getNewPart();
    // const hhatPart = intermix.getNewPart();

    // function init() {

    //     // const testNote = getNote(64, 4, samplerUID);
    //     // samplerActionCreators["NOTE"](testNote);

    //     // make a part and add it to the sequencer
    //     const note1 = getNote(32, 4, synthUID);
    //     const note2 = getNote(33, 4, synthUID);
    //     const note3 = getNote(44, 4, synthUID);
    //     const note4 = getNote(33, 8, synthUID);

    //     console.log(samplerUID);
    //     const hhNote = getNote(40, 8, samplerUID);

    //     synthPart1.addAction(note1, 0)
    //         .addAction(note1, 1)
    //         .addAction(note1, 2)
    //         .addAction(note1, 3)
    //         .addAction(note2, 4)
    //         .addAction(note3, 5)
    //         .addAction(note1, 6)
    //         .addAction(note1, 7)
    //         .addAction(note1, 8)
    //         .addAction(note1, 9)
    //         .addAction(note1, 10)
    //         .addAction(note1, 11)
    //         .addAction(note2, 12)
    //         .addAction(note3, 13)
    //         .addAction(note4, 14);

    //     hhatPart.addAction(hhNote, 0)
    //         .addAction(hhNote, 4)
    //         .addAction(hhNote, 8)
    //         .addAction(hhNote, 12);

    //     seqActionCreators["ADD_PART"]({ part: synthPart1, position: 0 });
    //     seqActionCreators["ADD_PART"]({ part: hhatPart, position: 0 });
    //     seqActionCreators["LOOP_ACTIVE"](true);

    //     const animeTest = (step) => {
    //         let blinker = document.getElementById("blink");
    //         if (step % 16 === 0) {
    //             blinker.style.backgroundColor = "red";
    //         } else {
    //             blinker.style.backgroundColor = "white";
    //         }
    //     }
    //     intermix.animate(animeTest);
    // }

    document.getElementById('resumeAudioContext').addEventListener('click', () => {
        intermix.resumeAudioContext();
        console.log("Audio Context Resumed");
    });

    document.getElementById("getstate").addEventListener('click', () => {
        console.log(intermix.getState());
    })

</script>

</html>